{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"3293d148178a4cf39f5b3026cb621eb1\" \n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://fish-health-bsc-resource-aiservices1116524949.openai.azure.com/\"\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "     openai_api_version=\"2023-07-01-preview\",\n",
    "     azure_deployment=\"gpt-4\",\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2023-07-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAVILY - Built in search engine tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.timeanddate.no/vaer/norge/bergen',\n",
       "  'content': 'V√¶ret i Bergen, Norge. Sol og m√•ne. V√¶ret i dag Time for time 14-dagers varsel I g√•r/v√¶ret som var Klima (gjennomsnitt) N√•.'},\n",
       " {'url': 'https://www.yr.no/nb/v√¶rvarsel/daglig-tabell/1-92416/Norge/Vestland/Bergen/Bergen',\n",
       "  'content': 'V√¶rvarsel for Bergen de neste 10 dagene. G√• til innholdet. En tjeneste fra Meteorologisk institutt og NRK ... Det ser ut til at JavaScript er skrudd av i nettleseren din. For √• f√• tilgang til alt av innhold p√• Yr anbefaler vi at du skrur p√• JavaScript. V√¶ret n√• ...'},\n",
       " {'url': 'https://www.yr.no/nb/v√¶rvarsel/daglig-tabell/1-513376/Norge/Vestland/Bergen',\n",
       "  'content': 'V√¶rvarsel for Bergen kommune de neste 10 dagene. G√• til innholdet. En tjeneste fra Meteorologisk institutt og NRK ... V√¶ret n√• . Temperatur 7 ¬∞ 7 ¬∞ ... Yr er en tjeneste fra. Redakt√∏r: Ingrid St√∏ver JensenAnsvarlig redakt√∏r: Vibeke F√ºrst HaugenMeteorologisk ansvarlig: Roar Sk√•lin.'},\n",
       " {'url': 'https://www.timeanddate.no/vaer/norge/bergen/langtids',\n",
       "  'content': 'V√¶ret i verden; V√¶ret der du er; Neste 14 dager; Time for time; V√¶ret i Norge; Siste 14 dager; Klima. Sol, m√•ne og universet. Sol og M√•ne: Alle tjenester; Soloppgang og solnedgang; ... 2-ukers utvidet v√¶rmelding for Bergen, Norge. Bla mot h√∏yre for √• se mer Forhold Vindstyrke og luftfuktighet Nedb√∏r Sola; Dag Temperatur V√¶ret F√∏les ...'},\n",
       " {'url': 'https://veret.gfi.uib.no/?action=forecasts',\n",
       "  'content': 'V√¶ret i Bergen -oppdaterte v√¶robservasjoner fra Geofysisk institutt V√¶ret i Bergen. Siste d√∏gn . Solposisjon ... Tidevann - Tidevann for Bergen og andre steder i Norge. DMI - Varsel for de neste 6-d√∏gn, ... Nettsiden er utviklet av Geofysisk institutt ved Universitetet i Bergen M√•linger av temperatur, vind, lufttrykk og luftfuktighet i ...'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "search.invoke(\"Hvordan er v√¶ret i Bergen, Norge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a vectorestore with the Langsmith documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = Chroma.from_documents(documents, AzureOpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in\", metadata={'description': 'Introduction', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mSkip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubProxyLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your\n",
      "\n",
      "about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in\n",
      "\n",
      "LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.Was this page helpful?NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith, developed by LangChain, is a platform specifically designed to help with building production-grade LLM applications. One of its features includes providing support for testing. This platform allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. Seamless integration with LangChain, the popular open-source framework for building with LLMs, is also provided. \n",
      "\n",
      "To get started with testing in LangSmith, you can refer to the tracing and evaluation quick start guides provided in the platform's documentation. Other sections in the user guide also explain the workflows that LangSmith supports at each stage of the LLM application lifecycle.\n",
      "\n",
      "Please note that before you begin, you'll need to create an account, obtain an API key, and configure your environment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': \"LangSmith, developed by LangChain, is a platform specifically designed to help with building production-grade LLM applications. One of its features includes providing support for testing. This platform allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. Seamless integration with LangChain, the popular open-source framework for building with LLMs, is also provided. \\n\\nTo get started with testing in LangSmith, you can refer to the tracing and evaluation quick start guides provided in the platform's documentation. Other sections in the user guide also explain the workflows that LangSmith supports at each stage of the LLM application lifecycle.\\n\\nPlease note that before you begin, you'll need to create an account, obtain an API key, and configure your environment.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current weather in √Öros in R√∏yken, Norway'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.timeanddate.com/weather/norway/royken', 'content': 'Current weather in R√∏yken and forecast for today, tomorrow, and next 14 days'}, {'url': 'https://www.timeanddate.com/weather/norway/royken/ext', 'content': 'R√∏yken 14 Day Extended Forecast. Weather. Time Zone. DST Changes. Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 42 ¬∞F. Cool. (Weather station: Hasle - MADIS Station, Norway).'}, {'url': 'https://weather.com/weather/tenday/l/√Öros+Viken+Norway?canonicalCityId=89fab4fd4a4171e85b636661f200f9395bee4a1777531f2fe70171f4e2585a80', 'content': 'Be prepared with the most accurate 10-day forecast for √Öros, Viken, Norway with highs, lows, chance of precipitation from The Weather Channel and Weather.com'}, {'url': 'https://www.wunderground.com/forecast/no/√•ros', 'content': 'Current Weather for Popular Cities . San Francisco, CA warning 48 ... √Öros, Viken, Norway 10-Day Weather Forecast star_ratehome. 17 ...'}, {'url': 'https://weather.com/en-MH/weather/tenday/l/√Öros+Viken+Norway?canonicalCityId=89fab4fd4a4171e85b636661f200f9395bee4a1777531f2fe70171f4e2585a80', 'content': 'Be prepared with the most accurate 10-day forecast for √Öros, Viken, Norway with highs, lows, chance of precipitation from The Weather Channel and Weather.com'}]\u001b[0m\u001b[32;1m\u001b[1;3mV√¶ret i √Öros i R√∏yken, Norge er for tiden kj√∏lig med en temperatur p√• 42 ¬∞F (5.56 ¬∞C). For mer detaljert informasjon og en 10-dagers v√¶rprognose, kan du bes√∏ke [Weather Channel](https://weather.com/weather/tenday/l/√Öros+Viken+Norway?canonicalCityId=89fab4fd4a4171e85b636661f200f9395bee4a1777531f2fe70171f4e2585a80) eller [Wunderground](https://www.wunderground.com/forecast/no/√•ros).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hvordan er v√¶ret i √Öros i R√∏yken, Norge?',\n",
       " 'output': 'V√¶ret i √Öros i R√∏yken, Norge er for tiden kj√∏lig med en temperatur p√• 42 ¬∞F (5.56 ¬∞C). For mer detaljert informasjon og en 10-dagers v√¶rprognose, kan du bes√∏ke [Weather Channel](https://weather.com/weather/tenday/l/√Öros+Viken+Norway?canonicalCityId=89fab4fd4a4171e85b636661f200f9395bee4a1777531f2fe70171f4e2585a80) eller [Wunderground](https://www.wunderground.com/forecast/no/√•ros).'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Hvordan er v√¶ret i √Öros i R√∏yken, Norge?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING IN MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. How can I assist you further?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob. How can I assist you further?'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEEP TRACK OF MESSAGES AUTOMATICALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
